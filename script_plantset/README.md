# Script Plantset - Mod√®le Vision-Langage Multimodal

Ensemble de scripts pour entra√Æner un mod√®le multimodal vision-langage puissant sur 133 classes de maladies de plantes, optimis√© pour TPU v4/v5/v6.

## üöÄ Fonctionnalit√©s

- **Architecture moderne** : Inspir√© de Florence-2, Qwen-VL, FLAVA, PaLM2-VAdapter
- **Support TPU** : Optimis√© pour TPU v4, v5, v6 avec torch_xla
- **Dataset multimodal** : Images + descriptions textuelles enrichies
- **Mixed precision** : Entra√Ænement acc√©l√©r√© avec AMP
- **Scalabilit√©** : Support multi-TPU et dataset sharding
- **M√©triques compl√®tes** : Classification + g√©n√©ration de texte (BLEU/ROUGE)

## üìÅ Structure des Scripts

```
script_plantset/
‚îú‚îÄ‚îÄ __init__.py              # Package initialisation
‚îú‚îÄ‚îÄ data_cleaner.py          # Nettoyage du dataset
‚îú‚îÄ‚îÄ text_mapper.py           # Mapping images + textes
‚îú‚îÄ‚îÄ dataset_loader.py        # DataLoader PyTorch scalable
‚îú‚îÄ‚îÄ model_builder.py         # Architecture multimodale
‚îú‚îÄ‚îÄ train.py                 # Entra√Ænement standard
‚îú‚îÄ‚îÄ evaluate.py              # √âvaluation compl√®te
‚îú‚îÄ‚îÄ infer.py                 # Pr√©dictions
‚îú‚îÄ‚îÄ scaler_tpu.py           # Support TPU
‚îî‚îÄ‚îÄ README.md               # Documentation
```

## üõ†Ô∏è Installation

```bash
# Installer les d√©pendances
pip install torch torchvision torch_xla
pip install transformers datasets
pip install scikit-learn matplotlib seaborn
pip install nltk rouge-score
pip install tqdm pillow

# Pour TPU (Google Cloud)
pip install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html
```

## üìä Pipeline Complet

### 1. Nettoyage des Donn√©es

```bash
python data_cleaner.py \
    --data-dir /path/to/dataset \
    --min-size 256 \
    --target-size 512 \
    --output-file dataset_clean.jsonl
```

### 2. Mapping Textuel

```bash
python text_mapper.py \
    --diseases-json /path/to/maladies_enrichies.json \
    --dataset-jsonl dataset_clean.jsonl \
    --output-file multimodal_dataset.jsonl \
    --language fr
```

### 3. Entra√Ænement Standard

```bash
python train.py \
    --jsonl-file multimodal_dataset.jsonl \
    --root-dir /path/to/images \
    --num-classes 133 \
    --vision-backbone resnet50 \
    --text-model microsoft/DialoGPT-medium \
    --epochs 100 \
    --batch-size 32 \
    --mixed-precision \
    --checkpoint-dir checkpoints
```

### 4. Entra√Ænement TPU

```bash
python scaler_tpu.py \
    --jsonl-file multimodal_dataset.jsonl \
    --root-dir /path/to/images \
    --num-classes 133 \
    --tpu-cores 8 \
    --epochs 100 \
    --batch-size 32 \
    --mixed-precision
```

### 5. √âvaluation

```bash
python evaluate.py \
    --checkpoint checkpoints/best_model.pth \
    --jsonl-file multimodal_dataset.jsonl \
    --root-dir /path/to/images \
    --num-classes 133 \
    --output-dir evaluation_results
```

### 6. Pr√©diction

```bash
python infer.py \
    --checkpoint checkpoints/best_model.pth \
    --num-classes 133 \
    --image /path/to/image.jpg \
    --text "Description optionnelle" \
    --top-k 5 \
    --generate-description
```

## üèóÔ∏è Architecture du Mod√®le

### Vision Encoder
- **Backbones support√©s** : ResNet18/50/101, EfficientNet, ViT
- **Pr√©-entra√Ænement** : ImageNet ou custom
- **Projection** : Linear + LayerNorm vers espace commun

### Text Encoder
- **Mod√®les support√©s** : BERT, RoBERTa, DialoGPT, LLaMA
- **Tokenisation** : HuggingFace tokenizers
- **Pooling** : Attention-based ou global average

### Fusion Module
- **Cross-Attention** : Attention crois√©e entre vision et texte
- **Multi-head** : 8 t√™tes d'attention par d√©faut
- **Layers** : 2 couches de fusion par d√©faut

### T√™tes de Sortie
- **Classification** : Softmax sur 133 classes
- **G√©n√©ration** : Embeddings pour descriptions textuelles

## ‚ö° Optimisations TPU

### Configuration Recommand√©e
- **TPU v4** : 8 c≈ìurs, batch_size=32-64
- **TPU v5** : 8 c≈ìurs, batch_size=64-128
- **TPU v6** : 8 c≈ìurs, batch_size=128-256

### Mixed Precision
```python
# Automatique avec torch_xla
use_mixed_precision=True
```

### Dataset Sharding
```python
# Automatique avec DataLoader
num_workers=4  # R√©duit pour TPU
pin_memory=False  # Pas n√©cessaire sur TPU
```

## üìà M√©triques

### Classification
- **Accuracy** : Pr√©cision globale
- **F1-Score** : Macro et weighted
- **AUC** : Area Under Curve
- **Confusion Matrix** : Visualisation des erreurs

### G√©n√©ration de Texte
- **BLEU** : Bilingual Evaluation Understudy
- **ROUGE** : Recall-Oriented Understudy for Gisting Evaluation
- **Perplexity** : Mesure de coh√©rence

## üîß Configuration Avanc√©e

### Mod√®le Personnalis√©
```python
from model_builder import create_multimodal_model

model = create_multimodal_model(
    num_classes=133,
    vision_backbone="efficientnet_b4",
    text_model="microsoft/DialoGPT-large",
    vision_dim=768,
    text_dim=768,
    fusion_dim=512,
    num_attention_heads=12,
    num_attention_layers=4
)
```

### DataLoader Personnalis√©
```python
from dataset_loader import create_data_module

data_module = create_data_module(
    jsonl_file="multimodal_dataset.jsonl",
    root_dir="/path/to/images",
    batch_size=64,
    image_size=384,
    text_length=256,
    augment=True
)
```

## üêõ D√©pannage

### Erreurs TPU
```bash
# V√©rifier la configuration TPU
python -c "import torch_xla; print(torch_xla.__version__)"

# Tester la connexion TPU
python -c "import torch_xla.core.xla_model as xm; print(xm.xla_device())"
```

### Erreurs de M√©moire
- R√©duire `batch_size`
- Utiliser `gradient_checkpointing=True`
- R√©duire `image_size` ou `text_length`

### Erreurs de Convergence
- Ajuster `learning_rate` (1e-5 √† 1e-3)
- Utiliser `warmup_steps`
- V√©rifier les `class_weights`

## üìö R√©f√©rences

- [Florence-2](https://arxiv.org/abs/2311.00542) - Microsoft
- [Qwen-VL](https://arxiv.org/abs/2308.12966) - Alibaba
- [FLAVA](https://arxiv.org/abs/2112.04482) - Facebook
- [PaLM2-VAdapter](https://arxiv.org/abs/2305.17023) - Google
- [torch_xla](https://github.com/pytorch/xla) - PyTorch TPU

## ü§ù Contribution

1. Fork le projet
2. Cr√©er une branche feature
3. Commit les changements
4. Push vers la branche
5. Ouvrir une Pull Request

## üìÑ Licence

MIT License - Voir LICENSE pour plus de d√©tails.

## üìû Support

- **Issues** : GitHub Issues
- **Discussions** : GitHub Discussions
- **Email** : support@smartagro.com

---

**D√©velopp√© par l'√©quipe Smart Agro** üå±








